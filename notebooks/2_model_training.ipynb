{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnn8p6CAtZatxRhUaCWE2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konan-91/OcularClassification/blob/master/notebooks/2_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model\n",
        "\n",
        "We now have four folders of topoplot images (which you should zip into *img_data.zip*) that will be used to train our model. We will utilise the fast.ai library - a deep learning library built ontop of PyTorch that provides high level abstractions for model training."
      ],
      "metadata": {
        "id": "bBo1nCRbWyTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from fastai.vision.all import *\n",
        "from fastai.vision.widgets import *"
      ],
      "metadata": {
        "id": "0Eol_6iKXajg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eC5Lhp5UjnKU"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/img_data.zip\n",
        "!rm /content/img_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our model's purpose is to classify blinks, we should split our data into positive and negative examples. However, we should ensure each cateogry is roughly the same size. We will use the entirety of the img_blinks dataset, and sample from img_rest, h_saccades, and v_saccades using a 50/25/25 split."
      ],
      "metadata": {
        "id": "CvGkeQ3uYdJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(path):\n",
        "    count = 0\n",
        "    for img in os.walk(path):\n",
        "        count += 1\n",
        "\n",
        "n_blinks = count_files('/content/img_data/img_blinks')\n",
        "n_v_saccades = count_files('/content/img_data/img_n_v_saccades')\n",
        "n_h_saccades = count_files('/content/img_data/img_h_saccades')\n",
        "n_rest = count_files('/content/img_data/img_rest')\n",
        "\n",
        "print(f'Number of blinks: {n_blinks}')\n",
        "print(f'Number of vertical saccades: {n_v_saccades}')\n",
        "print(f'Number of horizontal saccades: {n_h_saccades}')\n",
        "print(f'Number of rest: {n_rest}')"
      ],
      "metadata": {
        "id": "ZSrnJZNZX7q0",
        "outputId": "b24a98c7-5a88-4971-da54-6dfea3109a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of blinks: None\n",
            "Number of vertical saccades: None\n",
            "Number of horizontal saccades: None\n",
            "Number of rest: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWf4OrplWSme"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}